{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30b61190-61c1-4dd2-a9ec-acbadc8a52ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Supervised learning - Classification\n",
    "Goal of the excercise is to learn how to use Scikit-learn library for a classification tasks using Decision tree, SVM and NN. Moreover evaluate the performance of the proposed models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a70c5553-ad01-4d43-93fb-50c085f09a64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\asyncio\\base_events.py\", line 639, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\asyncio\\base_events.py\", line 1985, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\jirka\\AppData\\Local\\Temp\\ipykernel_19904\\1051840704.py\", line 2, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 53, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\pandas\\core\\ops\\__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\pandas\\core\\computation\\check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\numexpr\\__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\asyncio\\base_events.py\", line 639, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\asyncio\\base_events.py\", line 1985, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\jirka\\AppData\\Local\\Temp\\ipykernel_19904\\1051840704.py\", line 2, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\pandas\\__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 67, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py\", line 61, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\pandas\\core\\nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\jirka\\miniconda3\\Lib\\site-packages\\bottleneck\\__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:46\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr_name)\u001b[39m\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[32m     45\u001b[39m     sys.stderr.write(msg + tb_msg)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[32m     48\u001b[39m ret = \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mImportError\u001b[39m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.3 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix, auc, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948a2f23-7783-4218-b011-1690c65805c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Data Dictionary\n",
    "\n",
    "|Variable|Definition|Key|\n",
    "|:-------|:-------|:--------|\n",
    "|survival|Survival|0 = No, 1 = Yes|\n",
    "|pclass|Ticket class|1 = 1st, 2 = 2nd, 3 = 3rd|\n",
    "|sex|Sex||\n",
    "|Age|Age in years||\n",
    "|sibsp|# of siblings / spouses aboard the Titanic||\n",
    "|parch|# of parents / children aboard the Titanic||\n",
    "|ticket|Ticket number||\n",
    "|fare|Passenger fare||\n",
    "|cabin|Cabin number||\n",
    "|embarked|Port of Embarkation|C = Cherbourg, Q = Queenstown, S = Southampton|\n",
    "\n",
    "**pclass**: A proxy for socio-economic status (SES)\n",
    "1st = Upper\n",
    "2nd = Middle\n",
    "3rd = Lower\n",
    "\n",
    "**age**: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "**sibsp**: The dataset defines family relations in this way...\n",
    "Sibling = brother, sister, stepbrother, stepsister\n",
    "Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "\n",
    "**parch**: The dataset defines family relations in this way...\n",
    "Parent = mother, father\n",
    "Child = daughter, son, stepdaughter, stepson\n",
    "Some children travelled only with a nanny, therefore parch=0 for them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd915f1-bf25-4b51-8f86-863cd5a891c4",
   "metadata": {},
   "source": [
    "- Decision tree https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "- Train test split https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "- Accuracy https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "- Metrics https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "- K-Fold CV https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold\n",
    "- SVM https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d685ada-68b5-474a-84d5-5bfacd4a9eca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load the titanic.csv dataset\n",
    "- We want to create a model that predicts if a certain passanger survives or not, thus **survival** is the class label in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b9043cd-4e41-40b0-93e1-712d94d122b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_classification/titanic.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata_classification/titanic.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data_classification/titanic.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data_classification/titanic.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a3d400-65c8-4beb-bf62-5a524eb2eacf",
   "metadata": {},
   "source": [
    "## How many passangers survived?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1dfcb0-ac1c-4271-986a-fc5c017c760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Survived.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8e2c89-99da-455d-a856-ecb388c43d99",
   "metadata": {},
   "source": [
    "## We need to pre-process the data first\n",
    "- We want to use only numerical attributes as a model features\n",
    "- Certain attributes need to be dropped and some of them can be encoded\n",
    "\n",
    "### Which features would you drop and why?\n",
    "### Which features could be encoded and which methods would you use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07348831-2059-4df6-bd4b-3e8c7d7d23bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed1a75a-842a-4bb9-9d96-9f41e82faba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(exclude=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925eb694-ad0f-4c53-b524-c9f8ea3f7d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=np.number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1052ca31-34be-4775-b0d3-15c38e0b0593",
   "metadata": {},
   "source": [
    "## How many values are missing in the individual attributes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab4330d-7b20-4497-bb0c-03e86587c276",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d2f054-6572-4aa5-a3b5-3c9a24ed11e7",
   "metadata": {},
   "source": [
    "## Let's drop Name and Ticket features - these have no use for us now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8816c0bb-03c7-4b3b-be9b-af574c19728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Name', 'Ticket'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b1214c-278f-4fa6-8259-989ce7192b66",
   "metadata": {},
   "source": [
    "## Extract the deck identifier from the Cabin feature\n",
    "- Note: A = top deck, G = lowest deck\n",
    "- Change type to string\n",
    "- Filter the first letter using *apply* function\n",
    "- If the value is *nan* use *U* value as an replacement - this will mark the passangers with missing Cabin value\n",
    "- Replace the T value with A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715f6d85-aee5-4649-ba4b-dbff92c97a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Cabin = df.Cabin.astype(str).apply(lambda x: x[0] if x != 'nan' else 'U').replace({'T': 'A'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06e72ef-5465-4660-9f2f-78d449e1ac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Cabin.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074d8231-19b8-470d-a3a0-31efc63ad0fc",
   "metadata": {},
   "source": [
    "## The Age feature is tricky, we have multiple solutions for this, e.g.:\n",
    "- Drop the feature\n",
    "- Take the mean/median value to replace the missing value\n",
    "- Take a random list of ages that maintains the original statistical summary values.\n",
    "- Use a model to predict values based on the existing values.\n",
    "\n",
    "### We will use the second option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0042d5ec-7134-4019-b5fb-82847b3e8818",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=df.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5992687-87c1-476b-b674-0e4767e8f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Age = df.Age.fillna(df.Age.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cd2688-f10e-4cfe-a38f-16dd6f462170",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=df.Age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d69cd4-dfe3-4e37-9997-8fe135fa12dc",
   "metadata": {},
   "source": [
    "## Two passangers don't have the Embarked filled - we can drop these two rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb68d26-598e-4e2d-b782-63b6c38a70e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a377bb-ad92-4952-bff0-642e9f68efe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b71aa04-f392-4bbe-a2c3-9acd871665f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The last step of the pre-processing pipeline is to encode Sex, Cabin and Embarked features\n",
    "- We will use one-hot encoding for Sex and Embarked and Ordinal encoding for Cabin\n",
    "- Specify the encoding scheme for the ordinal encoding using an array in a form ['first', 'second', 'third', ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e4dcea-3112-4988-ba71-90cd87c1248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_categories = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'U']\n",
    "enc_cabin = OrdinalEncoder(categories=[cabin_categories])\n",
    "enc_cabin.fit_transform(df[['Cabin']])[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec43f04-0b47-4ef5-8a63-b1e2c0a3f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cabin'] = enc_cabin.fit_transform(df[['Cabin']])[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107cd80d-6c2c-4f8e-8e52-640314633c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_categories = ['male', 'female']\n",
    "enc_sex = OrdinalEncoder(categories=[sex_categories])\n",
    "df['Sex'] = enc_sex.fit_transform(df[['Sex']])[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e22af-b485-4721-b886-1b03eeca28bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18869dd-aca4-4ba0-9cb4-81d8891ba249",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df['Embarked'], prefix='Embarked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a32c1d1-cd69-4f07-b9fa-62a075b57460",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df['Embarked'], prefix='Embarked')], axis=1).drop('Embarked', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56cba21-7214-4cd2-acd6-e7507ffcba02",
   "metadata": {},
   "source": [
    "## Now we have the data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d78f97-2c46-4c5a-8297-d1effbeaa5ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0affd869-d673-4af1-b523-eb27e36bba64",
   "metadata": {},
   "source": [
    "## Let's start with splitting the data into the input and output part\n",
    "- Usually named as a *X* and *y* variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f021d0-28b1-4c2a-8e03-6070d3ace1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.loc[:, df.columns != 'Survived'], df.loc[:, 'Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c412ed1-20ff-47a8-9dfd-4f26a69cc624",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d44f9-ada3-4ed0-9b15-4c5c4d699b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c161813-24a7-46b5-9301-792c93810629",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Lets continue with train test split process.\n",
    "- Note that number of rows in the *X* and *y* in the Train/Test part of the data has to be equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4621df-36a4-4097-bb2c-4c8325f3b882",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cdb399-d902-428c-9fbc-fe985a446b03",
   "metadata": {},
   "source": [
    "## Create the Decision tree classifier instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b94962-d1f7-4451-a460-4f88d4cfe95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0509a62-5a8e-4f21-b229-b10d6a30f865",
   "metadata": {},
   "source": [
    "### Use *fit()* method for training of classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2f2156-e441-4321-ba53-69f59c648980",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b97786-6284-43fe-9f48-e52370106d9d",
   "metadata": {},
   "source": [
    "### Lets use trained model for the prediction part\n",
    "- Get predictions via the method *predict()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48e30c4-95e9-4625-967e-587b5099de67",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e17f70-c136-4eb0-b362-f19a8b787eb3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Can we evaluate our model?\n",
    "- There are multiple metrics used: Accuracy, Recall, Precision, F1-Score, etc.\n",
    "- Very useful is also creating a confusion matrix\n",
    "\n",
    "### Take a look at this [article](https://builtin.com/data-science/precision-and-recall) and [wiki](https://en.wikipedia.org/wiki/Precision_and_recall) about precision and recall\n",
    "- Beware the fact that as we increase precision, we decrease recall and vice-versa.\n",
    "\n",
    "- **Precision** is the ratio of correctly predicted positive observations to the total predicted positive observations. The question that this metric answer is of all passengers that labeled as survived, how many actually survived? High precision relates to the low false positive rate.\n",
    "\n",
    "- **Recall** is the ratio of correctly predicted positive observations to the all observations in actual class - yes. The question recall answers is: Of all the passengers that truly survived, how many did we label?\n",
    "\n",
    "- **F1 Score** is the harmonic mean of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. Intuitively it is not as easy to understand as accuracy, but F1 is usually more useful than accuracy, especially if you have an uneven class distribution. Accuracy works best if false positives and false negatives have similar cost. If the cost of false positives and false negatives are very different, it’s better to look at both Precision and Recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7aee0b-44d2-4609-95d9-c6ea223d717b",
   "metadata": {},
   "source": [
    "$ConfMatrix = \\begin{bmatrix}\n",
    "TP & FN\\\\\n",
    "FP & TN\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25742d4-061b-4cae-b0a6-31d75f8ec956",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0763f5-4d79-4ca5-9770-ecaad6f71a5e",
   "metadata": {},
   "source": [
    "## What does the confusion matrix tell us?\n",
    "- Where do we find true positives, false positives etc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298e88ae-1977-4689-b19f-6a408c141d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55121f43-8e77-4323-b237-370e99494790",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6bcc55-8e10-40c8-a9a0-8e76e56f0037",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dff2271-4ebd-4462-94ad-8686377f5bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c546e30-f5bd-4c9f-828b-84f3962bfa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5619f075-d02e-4fe2-90d6-8789c29e98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1434cb41-23c9-4a96-ba50-4b9aaac39d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98c7af7-8630-4c0e-accc-d996841d0bfa",
   "metadata": {},
   "source": [
    "## Can we improve our evaluation process?\n",
    "- Lets try crossvalidation process for decision tree model\n",
    "- https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "- **What is the difference between Pure and Stratified K-Fold?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69807937-742d-4286-ac50-c93d535acdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = KFold(n_splits=5)\n",
    "scores = list()\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    scores.append(f1_score(y_test, y_pred))\n",
    "    print(f'Survival ratio in train set: {y_train.value_counts(normalize=True)[1]:.2}; Survival ratio in test set: {y_test.value_counts(normalize=True)[1]:.2}')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d2d2bf-acad-4785-9f51-dc573f51f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "scores = list()\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    scores.append(f1_score(y_test, y_pred))\n",
    "    print(f'Survival ratio in train set: {y_train.value_counts(normalize=True)[1]:.2}; Survival ratio in test set: {y_test.value_counts(normalize=True)[1]:.2}')\n",
    "    \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736808ff-d46a-49a4-9a1d-b0f5516b37c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores), np.min(scores), np.max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c682878-0052-4cb8-a952-74e1e5cd3ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "scores = list()\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    scores.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ac65a5-55fa-4cfa-a52a-f08bf4a8b73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores), np.min(scores), np.max(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300a913e-e090-4ec5-b0c9-b7bb4b05810b",
   "metadata": {},
   "source": [
    "## Other way to use crossvalidation in Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57adda3-0367-4e3c-bba0-e2c7969be0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "scores = cross_val_score(clf, X, y, cv=5, scoring='f1')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f775d-7951-404d-999d-e5739d7e8ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores), np.min(scores), np.max(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2387a787-5a8a-4965-ad07-2a403cab2531",
   "metadata": {},
   "source": [
    "## Scale our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390d76d5-d09e-415e-ba08-2b5cc16788b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d41397-84d1-4f17-8468-58a51b7f7440",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "scores = cross_val_score(clf, X_scaled, y, cv=5, scoring='f1')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1f93a5-19ee-431e-9f7d-9aef917940a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores), np.min(scores), np.max(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6be346-e4e6-4a84-8222-9cdfef19e738",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Let's try other algorithms - SVM and ANN\n",
    "- SVM - https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "- SVM demo 1 - https://www.csie.ntu.edu.tw/~cjlin/libsvm/\n",
    "- SVM demo 2 - https://cs.stanford.edu/~karpathy/svmjs/demo/\n",
    "- SVM kernel trick https://towardsdatascience.com/optimization-loss-function-under-the-hood-part-iii-5dff33fa015d\n",
    "- ANN - https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "- ANN demo - https://playground.tensorflow.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde120b3-f518-41f4-9100-fb6afc7940fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 1: SVM (1b)\n",
    "- Take a look at the parameters of the SVM, e.g. C, kernel, gamma (in case of RBF)\n",
    "- **Try at least 5 different parameter's configurations**, use both linear and RBF kernel, you can also experiment with other\n",
    "- **Does the preprocesing help with classifier perfromance?** Use both **X** and **X_scaled** for training and evaluating\n",
    "- Tune the hyper-parameters and compare classification results after crossvalidation validation step\n",
    "    - When using RBF kernel show a relation between parameters C and gamma. You can create table or heatmap similar to the one in the lecture.\n",
    "    - **Write down to markdown cell which is better and why!**\n",
    "- *Implementation note in Sklearn: SVC(kernel='linear') might be slow, u can use LinearSVC instead.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43625666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fea63f1a-10e4-459e-836b-54f6bc346cf2",
   "metadata": {},
   "source": [
    "### Task 2: NN (1b)\n",
    "- Take a look at the parameters of the MLPClassifier, e.g. hidden_layer_sizes, activation, solver, max_iter\n",
    "- Tune the hyper-parameters and compare the ANN model proposed during the lecture\n",
    "    - Choose the ideal form of presentation for hyperparameter tuning results (e.g. table with scores, plot showing the score relation to some parameter, etc.)\n",
    "    - **Write down to markdown cell which is better and why!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1be1479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8369ced1",
   "metadata": {},
   "source": [
    "### Bonus task: OPTUNA (1b)\n",
    "Use **Optuna** library for hyperparameter tuning process for one of previous classification methods (SVM, ANN).\n",
    "\n",
    "A short list with some materials for this task:\n",
    "- Hyperparameter tuning blog 1 https://medium.com/@iqra.bismi/hyper-parameter-tuning-of-machine-learning-models-using-optuna-f1905547937f\n",
    "- Hyperparameter tuning blog 2 https://medium.com/@abdalrahman_shahrour/optuna-vs-gridsearch-57227556c450\n",
    "- https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/005_visualization.html\n",
    "- https://github.com/optuna/optuna\n",
    "- https://github.com/optuna/optuna-dashboard and https://optuna.github.io/optuna-dashboard/\n",
    "\n",
    "**What is the difference in using the Optuna instead of grid search?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a955c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
